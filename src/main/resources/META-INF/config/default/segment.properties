#
# training and test files
#


#inputDicts = data/dict/aifang-spec.dict,data/dict/aifang-loupan.dict,data/dict/aifang-metro.dict,data/dict/aifang-other.dict,data/dict/aifang-regions.dict,data/dict/aifang-road.dict,data/dict/aifang-synonyms.dict
#newInputDict = data/dict/aifang-new.dict
#
#aifangSerDictionary = data/aifang-chris.ser.gz
#serDictionary = data/dict-chris8.ser.gz,data/aifang-chris.ser.gz
#
#loadClassifier = data/ctb/ctb.gz
#aifangCtbClassifier = data/aifang-ctb.ser.gz
#
#trainFileList = data/train/aifang-ctb.train.seg,data/train/ctb6.train.seg
#newTrainFile = data/train/aifang-new.train.seg
#
#serializeTo = data/aifang-ctb.ser.gz
##serializeToText = data/aifang-ctb.gz


inputDicts = /home/www/data/dict/aifang-spec.dict,/home/www/data/dict/aifang-loupan.dict,/home/www/data/dict/aifang-metro.dict,/home/www/data/dict/aifang-other.dict,/home/www/data/dict/aifang-regions.dict,/home/www/data/dict/aifang-road.dict,/home/www/data/dict/aifang-synonyms.dict
newInputDict = /home/www/data/dict/aifang-new.dict

aifangSerDictionary = /home/www/data/aifang-chris.ser.gz
serDictionary = /home/www/data/dict-chris8.ser.gz,/home/www/data/aifang-chris.ser.gz

loadClassifier = /home/www/data/ctb/ctb.gz
aifangOnlineCtbClassifier = /home/www/data/ctb/ctb.gz
aifangOfflineCtbClassifier = /home/www/data/aifang-ctb.ser.gz

trainFileList = /home/www/data/train/aifang-ctb.train.seg,/home/www/data/train/ctb6.train.seg
newTrainFile = /home/www/data/train/aifang-new.train.seg

serializeTo = /home/www/data/aifang-ctb.ser.gz

#serializeToText = /home/www/data/aifang-ctb.gz




# It requires subdirectory dict under it!
# used to be:
# sighanCorporaDict = /juicy/u2/nlp2/data/chinese-segmenter/gale2007/ctb6/
# perhaps that was moved to here?
sighanCorporaDict = /home/www/data

# map [testMap, trainMap]
#
# you MUST call answer answer
# if you use our reading/writing, call it "word"
# if you write your own, you can call it whatever you want
#
map = char=0,answer=1
backgroundSymbol=1
removeBackgroundSingletonFeatures=true
saveFeatureIndexToDisk=true

#
# how to read the input [keep this line]
#
readerAndWriter=edu.stanford.nlp.wordseg.Sighan2005DocumentReaderAndWriter

plainTextDocumentReaderAndWriter=edu.stanford.nlp.wordseg.Sighan2005DocumentReaderAndWriter

#
# how to do optimization.
# higher QNsize = less time, fewer iterations, more memory
#
useQN = true
QNsize = 15

# This value has been set to be roughly optimal
sigma = 3.0


# use the chinese feature factory
#
featureFactory = edu.stanford.nlp.wordseg.Gale2007ChineseSegmenterFeatureFactory

inputEncoding = UTF-8
outputEncoding = UTF-8

# chinese features
maxLeft=1
useWord1=true
useWord2=true
useFeaturesC4gram=true
useFeaturesCpC4gram=true
useUnicodeType=true
useUnicodeType4gram=true
useUnicodeBlock=true
useShapeStrings=true
useShapeStrings1=true
useShapeStrings3=true
useShapeStrings4=true
useShapeStrings5=true

# useDict2=true
useCTBChar2=true
useRule2=true
useWordn=true


useDictionaryConjunctions=true
expandMidDot=true

# useChPos=true

# printFeatures = ctb-train

# runtime testing
keepEnglishWhitespaces=true
keepAllWhitespaces = true
sighanPostProcessing = true
